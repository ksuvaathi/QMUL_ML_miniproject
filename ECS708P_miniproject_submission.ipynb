{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ECS708P_miniproject_submission.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 Truffle",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91MsGMTna_P9"
      },
      "source": [
        "# ECS708P mini-project submission\n",
        "\n",
        "The mini-project consists of two components:\n",
        "\n",
        "\n",
        "1.   **Basic solution** : Using the MLEnd dataset, build a model that predicts the intonation of a short audio segment.\n",
        "2.   **Advanced solution** : There are two options. (i) Formulate a machine learning problem that can be attempted using the MLEnd dataset and build a solution model (e.g. identify a numeral in a short sequence). (ii) Create a product that uses the functionality provided by a model trained on the MLEnd dataset (e.g. identify a number based on the identification of individual numerals).  \n",
        "\n",
        "\n"
       
     
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkkVHoP0tEhM"
      },
      "source": [
        "#Mini Project\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaGn4ICrfqXZ"
      },
      "source": [
        "\n",
        "\n",
        "# 1 Basic solution\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8G7B8Q1ogUBt",
        "outputId": "6d19d110-cc39-45be-aeed-7f742d7d2046"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os, sys, re, pickle, glob\n",
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "#from IPython.display import Audio\n",
        "import IPython.display as ipd\n",
        "from tqdm import tqdm\n",
        "import librosa\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtWC-I0Y9W1N",
        "outputId": "6397921f-f3e6-4751-e6eb-6a27144277e0"
      },
      "source": [
        "path = '/content/drive/MyDrive/MScProject/MLEnd'\n",
        "os.listdir(path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['trainingMLEnd.csv', 'training', 'training.zip']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_dt_e0tyl6M",
        "outputId": "8273d7e2-b212-418e-d436-7af1556bfe22"
      },
      "source": [
        "files = glob.glob('/content/drive/MyDrive/Data/MLEnd/training/*/*.wav')\n",
        "len(files)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "LcntCZhe0GT7",
        "outputId": "bfd7c12e-1de9-4194-ecc3-6a140cf0ab59"
      },
      "source": [
        "labels = pd.read_csv('/content/drive/MyDrive/Data/MLEnd/trainingMLEnd.csv')\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File ID</th>\n",
              "      <th>digit_label</th>\n",
              "      <th>participant</th>\n",
              "      <th>intonation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000000.wav</td>\n",
              "      <td>4</td>\n",
              "      <td>S73</td>\n",
              "      <td>question</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000001.wav</td>\n",
              "      <td>2</td>\n",
              "      <td>S88</td>\n",
              "      <td>excited</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000002.wav</td>\n",
              "      <td>70</td>\n",
              "      <td>S5</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0000003.wav</td>\n",
              "      <td>2</td>\n",
              "      <td>S85</td>\n",
              "      <td>bored</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0000004.wav</td>\n",
              "      <td>4</td>\n",
              "      <td>S30</td>\n",
              "      <td>excited</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>0019995.wav</td>\n",
              "      <td>90</td>\n",
              "      <td>S163</td>\n",
              "      <td>excited</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>0019996.wav</td>\n",
              "      <td>10</td>\n",
              "      <td>S99</td>\n",
              "      <td>question</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>0019997.wav</td>\n",
              "      <td>90</td>\n",
              "      <td>S46</td>\n",
              "      <td>question</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>0019998.wav</td>\n",
              "      <td>19</td>\n",
              "      <td>S13</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>0019999.wav</td>\n",
              "      <td>20</td>\n",
              "      <td>S101</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows Ã— 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           File ID  digit_label participant intonation\n",
              "0      0000000.wav            4         S73   question\n",
              "1      0000001.wav            2         S88    excited\n",
              "2      0000002.wav           70          S5    neutral\n",
              "3      0000003.wav            2         S85      bored\n",
              "4      0000004.wav            4         S30    excited\n",
              "...            ...          ...         ...        ...\n",
              "19995  0019995.wav           90        S163    excited\n",
              "19996  0019996.wav           10         S99   question\n",
              "19997  0019997.wav           90         S46   question\n",
              "19998  0019998.wav           19         S13    neutral\n",
              "19999  0019999.wav           20        S101    neutral\n",
              "\n",
              "[20000 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKnKK8j-za45"
      },
      "source": [
        "The below cell defines a function that gets the pitch of an audio signal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZu4-oBYpfeH"
      },
      "source": [
        "def getPitch(x,fs,winLen=0.02):\n",
        "  #winLen = 0.02 \n",
        "  p = winLen*fs\n",
        "  frame_length = int(2**int(p-1).bit_length())\n",
        "  hop_length = frame_length//2\n",
        "  f0, voiced_flag, voiced_probs = librosa.pyin(y=x, fmin=80, fmax=450, sr=fs,\n",
        "                                                 frame_length=frame_length,hop_length=hop_length)\n",
        "  return f0,voiced_flag"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4W7bKtlpItAS"
      },
      "source": [
        "The problem is to identify the intonation of a short audio signal.The next cell defines a function that takes a number of files and creates a NumPy array containing the 4 audio features used as predictors (X) and their labels (y)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wF92dQ3pivt"
      },
      "source": [
        "def getXy(files,labels_file,scale_audio=False):\n",
        "  X,y =[],[]\n",
        "  for file in tqdm(files):\n",
        "    fileID = file.split('/')[-1]\n",
        "    yi = list(labels_file[labels_file['File ID']==fileID]['intonation'])[0]\n",
        "    fs = None # if None, fs would be 22050\n",
        "    x, fs = librosa.load(file,sr=fs)\n",
        "    if scale_audio: x = x/np.max(np.abs(x))\n",
        "    f0, voiced_flag = getPitch(x,fs,winLen=0.02)\n",
        "      \n",
        "    power = np.sum(x**2)/len(x)\n",
        "    pitch_mean = np.nanmean(f0) if np.mean(np.isnan(f0))<1 else 0\n",
        "    pitch_std  = np.nanstd(f0) if np.mean(np.isnan(f0))<1 else 0\n",
        "    voiced_fr = np.mean(voiced_flag)\n",
        "\n",
        "    xi = [power,pitch_mean,pitch_std,voiced_fr]\n",
        "    X.append(xi)\n",
        "    y.append(yi)\n",
        "  return np.array(X),np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ee3QYGyBc5sb"
      },
      "source": [
        "Only 500 files will be used to train and test the model.Using all 20000 files will be time consuming."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ft-qMAFQ14tL",
        "outputId": "7420f1e4-c7a6-4c65-ee3d-92f37e534db2"
      },
      "source": [
        "X,y = getXy(files[:500],labels_file=labels,scale_audio=True)\n",
        "\n",
        "# If you want to use all 20000 files, run next line instead\n",
        "#X,y = getXy(files,labels_file=labels,scale_audio=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [03:49<00:00,  2.18it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjOdhr0mppWe",
        "outputId": "ae7e9f0b-261f-47fe-a60a-df902d5ad483"
      },
      "source": [
        "print('The shape of X is', X.shape) \n",
        "print('The shape of y is', y.shape)\n",
        "print('The labels vector is', y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of X is (500, 4)\n",
            "The shape of y is (500,)\n",
            "The labels vector is ['bored' 'question' 'excited' 'excited' 'question' 'excited' 'neutral'\n",
            " 'bored' 'neutral' 'neutral' 'neutral' 'bored' 'bored' 'question'\n",
            " 'neutral' 'bored' 'neutral' 'neutral' 'question' 'excited' 'neutral'\n",
            " 'excited' 'bored' 'excited' 'bored' 'neutral' 'bored' 'bored' 'bored'\n",
            " 'excited' 'question' 'excited' 'neutral' 'neutral' 'neutral' 'neutral'\n",
            " 'neutral' 'question' 'question' 'bored' 'question' 'bored' 'bored'\n",
            " 'question' 'neutral' 'bored' 'excited' 'bored' 'bored' 'question'\n",
            " 'question' 'bored' 'bored' 'question' 'excited' 'neutral' 'bored'\n",
            " 'neutral' 'neutral' 'neutral' 'excited' 'bored' 'excited' 'excited'\n",
            " 'question' 'excited' 'question' 'bored' 'question' 'neutral' 'bored'\n",
            " 'bored' 'neutral' 'bored' 'question' 'neutral' 'excited' 'question'\n",
            " 'excited' 'question' 'neutral' 'excited' 'neutral' 'excited' 'neutral'\n",
            " 'neutral' 'excited' 'excited' 'bored' 'bored' 'question' 'question'\n",
            " 'question' 'bored' 'neutral' 'bored' 'question' 'question' 'bored'\n",
            " 'bored' 'bored' 'bored' 'neutral' 'question' 'excited' 'neutral' 'bored'\n",
            " 'question' 'question' 'excited' 'excited' 'neutral' 'question' 'neutral'\n",
            " 'bored' 'excited' 'neutral' 'excited' 'question' 'excited' 'excited'\n",
            " 'excited' 'bored' 'bored' 'neutral' 'neutral' 'bored' 'question'\n",
            " 'excited' 'excited' 'bored' 'excited' 'bored' 'neutral' 'question'\n",
            " 'excited' 'neutral' 'question' 'bored' 'question' 'excited' 'question'\n",
            " 'neutral' 'question' 'neutral' 'question' 'excited' 'question' 'bored'\n",
            " 'neutral' 'question' 'excited' 'question' 'excited' 'question' 'bored'\n",
            " 'bored' 'bored' 'bored' 'bored' 'bored' 'excited' 'neutral' 'excited'\n",
            " 'neutral' 'question' 'question' 'bored' 'neutral' 'bored' 'excited'\n",
            " 'bored' 'excited' 'excited' 'excited' 'question' 'question' 'excited'\n",
            " 'question' 'neutral' 'bored' 'excited' 'question' 'bored' 'neutral'\n",
            " 'excited' 'neutral' 'question' 'neutral' 'neutral' 'neutral' 'neutral'\n",
            " 'excited' 'question' 'question' 'bored' 'excited' 'question' 'bored'\n",
            " 'bored' 'question' 'neutral' 'neutral' 'bored' 'bored' 'excited'\n",
            " 'question' 'neutral' 'excited' 'question' 'excited' 'neutral' 'bored'\n",
            " 'neutral' 'bored' 'bored' 'question' 'neutral' 'bored' 'bored' 'excited'\n",
            " 'neutral' 'bored' 'neutral' 'neutral' 'neutral' 'excited' 'neutral'\n",
            " 'bored' 'neutral' 'bored' 'excited' 'question' 'neutral' 'neutral'\n",
            " 'excited' 'neutral' 'bored' 'bored' 'bored' 'question' 'question'\n",
            " 'excited' 'neutral' 'neutral' 'neutral' 'excited' 'question' 'neutral'\n",
            " 'question' 'question' 'question' 'neutral' 'question' 'bored' 'bored'\n",
            " 'excited' 'neutral' 'neutral' 'neutral' 'bored' 'neutral' 'excited'\n",
            " 'question' 'question' 'question' 'bored' 'excited' 'neutral' 'bored'\n",
            " 'question' 'excited' 'question' 'neutral' 'neutral' 'neutral' 'question'\n",
            " 'neutral' 'excited' 'neutral' 'excited' 'neutral' 'question' 'excited'\n",
            " 'bored' 'neutral' 'question' 'neutral' 'question' 'question' 'bored'\n",
            " 'excited' 'question' 'excited' 'bored' 'question' 'neutral' 'question'\n",
            " 'excited' 'excited' 'neutral' 'bored' 'bored' 'neutral' 'excited'\n",
            " 'excited' 'question' 'neutral' 'bored' 'bored' 'excited' 'excited'\n",
            " 'excited' 'neutral' 'excited' 'question' 'bored' 'bored' 'bored'\n",
            " 'question' 'question' 'neutral' 'excited' 'excited' 'excited' 'bored'\n",
            " 'neutral' 'question' 'question' 'bored' 'neutral' 'excited' 'excited'\n",
            " 'neutral' 'question' 'neutral' 'question' 'excited' 'neutral' 'bored'\n",
            " 'bored' 'neutral' 'excited' 'question' 'bored' 'bored' 'question' 'bored'\n",
            " 'excited' 'excited' 'excited' 'question' 'excited' 'neutral' 'question'\n",
            " 'bored' 'bored' 'neutral' 'excited' 'neutral' 'question' 'excited'\n",
            " 'question' 'excited' 'question' 'neutral' 'bored' 'excited' 'neutral'\n",
            " 'excited' 'neutral' 'question' 'bored' 'excited' 'neutral' 'question'\n",
            " 'excited' 'neutral' 'excited' 'neutral' 'question' 'bored' 'neutral'\n",
            " 'excited' 'neutral' 'bored' 'neutral' 'excited' 'neutral' 'bored' 'bored'\n",
            " 'excited' 'question' 'excited' 'neutral' 'bored' 'neutral' 'neutral'\n",
            " 'bored' 'bored' 'question' 'bored' 'bored' 'excited' 'question'\n",
            " 'question' 'excited' 'excited' 'neutral' 'excited' 'bored' 'neutral'\n",
            " 'bored' 'neutral' 'neutral' 'bored' 'question' 'question' 'excited'\n",
            " 'excited' 'excited' 'neutral' 'question' 'bored' 'question' 'bored'\n",
            " 'neutral' 'bored' 'question' 'excited' 'neutral' 'neutral' 'question'\n",
            " 'excited' 'excited' 'neutral' 'question' 'question' 'question' 'excited'\n",
            " 'bored' 'question' 'bored' 'neutral' 'excited' 'neutral' 'neutral'\n",
            " 'question' 'excited' 'excited' 'question' 'neutral' 'neutral' 'neutral'\n",
            " 'bored' 'bored' 'excited' 'question' 'bored' 'bored' 'excited' 'question'\n",
            " 'question' 'question' 'bored' 'bored' 'neutral' 'neutral' 'excited'\n",
            " 'neutral' 'question' 'bored' 'bored' 'question' 'question' 'excited'\n",
            " 'excited' 'excited' 'neutral' 'bored' 'excited' 'question' 'excited'\n",
            " 'bored' 'neutral' 'excited' 'neutral' 'neutral' 'excited' 'bored'\n",
            " 'neutral' 'question' 'bored' 'excited' 'bored' 'neutral' 'excited'\n",
            " 'question' 'excited' 'excited']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0s6UCAg1Jncw"
      },
      "source": [
        "As part of preprocessing the dataset, all items with a NaN are removed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozIn9siGpsqu",
        "outputId": "b7765fc5-62f7-402c-e7fb-4326899d3678"
      },
      "source": [
        "# If nan sample, remove them\n",
        "if np.sum(np.isnan(X)):\n",
        "  idx = np.isnan(X).sum(1)>0\n",
        "  X = X[~idx]\n",
        "  y = y[~idx]\n",
        "print(np.sum(np.isnan(X)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAgZSyiKJ70z"
      },
      "source": [
        "To identify the best model to solve this problem, a cross-validation approach was taken. Using K-fold cross validation approach, various machine learning models were compared as seen in the next cell. Default hyperparameters were used for all models. There will be ten splits to ensure the datatset is divided evenly and there is sufficient data in each fold."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "EXtovb7W1bDI",
        "outputId": "9f2604dd-46cf-4a58-b8a3-d191348dd4df"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import model_selection\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "#create list of machine learning models\n",
        "models = []\n",
        "models.append(('NB',GaussianNB()))\n",
        "models.append(('RFC',RandomForestClassifier()))\n",
        "models.append(('KNN', KNeighborsClassifier()))\n",
        "models.append(('CART', DecisionTreeClassifier()))\n",
        "models.append(('SVM', SVC()))\n",
        "results = [] #list for results during cross validation\n",
        "names = [] # list of all model names.Required when printing out results\n",
        "\n",
        "for name, model in models:\n",
        "\tkfold = model_selection.KFold(n_splits=10)\n",
        "\tcv_results = model_selection.cross_val_score(model, X, y, cv=kfold, scoring='accuracy')\n",
        "\tresults.append(cv_results)\n",
        "\tnames.append(name)\n",
        " #get average results from all folds\n",
        "\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "\tprint(msg)\n",
        " \n",
        "#plotting boxplot to compare results of each model\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Algorithm Comparison')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NB: 0.440000 (0.057271)\n",
            "RFC: 0.470000 (0.067676)\n",
            "KNN: 0.396000 (0.041761)\n",
            "CART: 0.394000 (0.094678)\n",
            "SVM: 0.378000 (0.026000)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nJ8zy3UKwF4"
      },
      "source": [
        "The above cell was executed multiple times to understand the best model overall. The Random Trees Classifier obtained the highest accuracy among all models whenever executed. On the other hand, the decision tree classifier performed the worst.The boxplot shows the accuracy scores across each cross validation fold for each algorithm.\n",
        "\n",
        "\n",
        "From the results it is clear that it would be best to study Random Forest Classifiers further. Using GridSearch, the next cell attempts to improve the accuracy of this classifier. Various hyperparameters were tested to identfy the best version of the model. The parameter grid included the default hyperparameters so results could be compared and understand why this classifer performed the best."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zx7hgvGpwN_R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8d2e2c0-f0e7-42db-a1bc-722c053063ef"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=0)\n",
        "\n",
        "#normalisation\n",
        "mean = X_train.mean(0)\n",
        "sd =  X_train.std(0)\n",
        "\n",
        "X_train = (X_train-mean)/sd\n",
        "X_test  = (X_test-mean)/sd\n",
        "\n",
        "#parameters being tested\n",
        "tuned_parameters = param_grid = {\n",
        "    'max_depth': [None,3,4],\n",
        "    'min_samples_split': [2,3,4],\n",
        "    'n_estimators': [50,100, 200]\n",
        "}\n",
        "\n",
        "print(\"Tuning hyper-parameters for accuracy\")\n",
        "print()\n",
        "\n",
        "clf = GridSearchCV(RandomForestClassifier(), tuned_parameters, scoring='accuracy')\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters set found on development set:\")\n",
        "print()\n",
        "print(clf.best_params_)\n",
        "print()\n",
        "print(\"Grid scores on development set:\")\n",
        "print()\n",
        "means = clf.cv_results_['mean_test_score']\n",
        "stds = clf.cv_results_['std_test_score']\n",
        "#printing out accuracy details for each type of RFC\n",
        "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "  print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
        "  print()\n",
        "  print(\"Detailed classification report:\")\n",
        "  print()\n",
        "  y_true, y_pred = y_test, clf.predict(X_test)\n",
        "  print(classification_report(y_true, y_pred))\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tuning hyper-parameters for accuracy\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "\n",
            "Grid scores on development set:\n",
            "\n",
            "0.423 (+/-0.106) for {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 50}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       bored       0.59      0.36      0.45        36\n",
            "     excited       0.43      0.57      0.49        37\n",
            "     neutral       0.49      0.62      0.55        39\n",
            "    question       0.60      0.47      0.53        38\n",
            "\n",
            "    accuracy                           0.51       150\n",
            "   macro avg       0.53      0.50      0.50       150\n",
            "weighted avg       0.53      0.51      0.50       150\n",
            "\n",
            "\n",
            "0.420 (+/-0.043) for {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       bored       0.59      0.36      0.45        36\n",
            "     excited       0.43      0.57      0.49        37\n",
            "     neutral       0.49      0.62      0.55        39\n",
            "    question       0.60      0.47      0.53        38\n",
            "\n",
            "    accuracy                           0.51       150\n",
            "   macro avg       0.53      0.50      0.50       150\n",
            "weighted avg       0.53      0.51      0.50       150\n",
            "\n",
            "\n",
            "0.420 (+/-0.064) for {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       bored       0.59      0.36      0.45        36\n",
            "     excited       0.43      0.57      0.49        37\n",
            "     neutral       0.49      0.62      0.55        39\n",
            "    question       0.60      0.47      0.53        38\n",
            "\n",
            "    accuracy                           0.51       150\n",
            "   macro avg       0.53      0.50      0.50       150\n",
            "weighted avg       0.53      0.51      0.50       150\n",
            "\n",
            "\n",
            "0.414 (+/-0.057) for {'max_depth': None, 'min_samples_split': 3, 'n_estimators': 50}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       bored       0.59      0.36      0.45        36\n",
            "     excited       0.43      0.57      0.49        37\n",
            "     neutral       0.49      0.62      0.55        39\n",
            "    question       0.60      0.47      0.53        38\n",
            "\n",
            "    accuracy                           0.51       150\n",
            "   macro avg       0.53      0.50      0.50       150\n",
            "weighted avg       0.53      0.51      0.50       150\n",
            "\n",
            "\n",
            "0.417 (+/-0.052) for {'max_depth': None, 'min_samples_split': 3, 'n_estimators': 100}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       bored       0.59      0.36      0.45        36\n",
            "     excited       0.43      0.57      0.49        37\n",
            "     neutral       0.49      0.62      0.55        39\n",
            "    question       0.60      0.47      0.53        38\n",
            "\n",
            "    accuracy                           0.51       150\n",
            "   macro avg       0.53      0.50      0.50       150\n",
            "weighted avg       0.53      0.51      0.50       150\n",
            "\n",
            "\n",
            "0.414 (+/-0.048) for {'max_depth': None, 'min_samples_split': 3, 'n_estimators': 200}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       bored       0.59      0.36      0.45        36\n",
            "     excited       0.43      0.57      0.49        37\n",
            "     neutral       0.49      0.62      0.55        39\n",
            "    question       0.60      0.47      0.53        38\n",
            "\n",
            "    accuracy                           0.51       150\n",
            "   macro avg       0.53      0.50      0.50       150\n",
            "weighted avg       0.53      0.51      0.50       150\n",
            "\n",
            "\n",
            "0.449 (+/-0.082) for {'max_depth': None, 'min_samples_split': 4, 'n_estimators': 50}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       bored       0.59      0.36      0.45        36\n",
            "     excited       0.43      0.57      0.49        37\n",
            "     neutral       0.49      0.62      0.55        39\n",
            "    question       0.60      0.47      0.53        38\n",
            "\n",
            "    accuracy                           0.51       150\n",
            "   macro avg       0.53      0.50      0.50       150\n",
            "weighted avg       0.53      0.51      0.50       150\n",
            "\n",
            "\n",
            "0.446 (+/-0.066) for {'max_depth': None, 'min_samples_split': 4, 'n_estimators': 100}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       bored       0.59      0.36      0.45        36\n",
            "     excited       0.43      0.57      0.49        37\n",
            "     neutral       0.49      0.62      0.55        39\n",
            "    question       0.60      0.47      0.53        38\n",
            "\n",
            "    accuracy                           0.51       150\n",
            "   macro avg       0.53      0.50      0.50       150\n",
            "weighted avg       0.53      0.51      0.50       150\n",
            "\n",
            "\n",
            "0.420 (+/-0.102) for {'max_depth': None, 'min_samples_split': 4, 'n_estimators': 200}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       bored       0.59      0.36      0.45        36\n",
            "     excited       0.43      0.57      0.49        37\n",
            "     neutral       0.49      0.62      0.55        39\n",
            "    question       0.60      0.47      0.53        38\n",
            "\n",
            "    accuracy                           0.51       150\n",
            "   macro avg       0.53      0.50      0.50       150\n",
            "weighted avg       0.53      0.51      0.50       150\n",
            "\n",
            "\n",
            "0.477 (+/-0.086) for {'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 50}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       bored       0.59      0.36      0.45        36\n",
            "     excited       0.43      0.57      0.49        37\n",
            "     neutral       0.49      0.62      0.55        39\n",
            "    question       0.60      0.47      0.53        38\n",
            "\n",
            "    accuracy                           0.51       150\n",
            "   macro avg       0.53      0.50      0.50       150\n",
            "weighted avg       0.53      0.51      0.50       150\n",
            "\n",
            "\n",
            "0.491 (+/-0.119) for {'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       bored       0.59      0.36      0.45        36\n",
            "     excited       0.43      0.57      0.49        37\n",
            "     neutral       0.49      0.62      0.55        39\n",
            "    question       0.60      0.47      0.53        38\n",
            "\n",
            "    accuracy                           0.51       150\n",
            "   macro avg       0.53      0.50      0.50       150\n",
            "weighted avg       0.53      0.51      0.50       150\n",
            "\n",
            "\n",
            "0.469 (+/-0.119) for {'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 200}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       bored       0.59      0.36      0.45        36\n",
            "     excited       0.43      0.57      0.49        37\n",
            "     neutral       0.49      0.62      0.55        39\n",
            "    question       0.60      0.47      0.53        38\n",
            "\n",
            "    accuracy                           0.51       150\n",
            "   macro avg       0.53      0.50      0.50       150\n",
            "weighted avg       0.53      0.51      0.50       150\n",
            "\n",
            "\n",
            "0.489 (+/-0.100) for {'max_depth': 3, 'min_samples_split': 3, 'n_estimators': 50}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       bored       0.59      0.36      0.45        36\n",
            "     excited       0.43      0.57      0.49        37\n",
            "     neutral       0.49      0.62      0.55        39\n",
            "    question       0.60      0.47      0.53        38\n",
            "\n",
            "    accuracy                           0.51       150\n",
            "   macro avg       0.53      0.50      0.50       150\n",
            "weighted avg       0.53      0.51      0.50       150\n",
            "\n",
            "\n",
            "0.477 (+/-0.086) for {'max_depth': 3, 'min_samples_split': 3, 'n_estimators': 100}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       bored       0.59      0.36      0.45        36\n",
            "     excited       0.43      0.57      0.49        37\n",
            "     neutral       0.49      0.62      0.55        39\n",
            "    question       0.60      0.47      0.53        38\n",
            "\n",
            "    accuracy                           0.51       150\n",
            "   macro avg       0.53      0.50      0.50       150\n",
            "weighted avg       0.53      0.51      0.50       150\n",
            "\n",
            "\n",
            "0.466 (+/-0.111) for {'max_depth': 3, 'min_samples_split': 3, 'n_estimators': 200}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       bored       0.59      0.36      0.45        36\n",
            "     excited       0.43      0.57      0.49        37\n",
            "     neutral       0.49      0.62      0.55        39\n",
            "    question       0.60      0.47      0.53        38\n",
            "\n",
            "    accuracy                           0.51       150\n",
            "   macro avg       0.53      0.50      0.50       150\n",
            "weighted avg       0.53      0.51      0.50       150\n",
            "\n",
            "\n",
            "0.466 (+/-0.086) for {'max_depth': 3, 'min_samples_split': 4, 'n_estimators': 50}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       bored       0.59      0.36      0.45        36\n",
            "     excited       0.43      0.57      0.49        37\n",
            "     neutral       0.49      0.62      0.55        39\n",
            "    question       0.60      0.47      0.53        38\n",
            "\n",
            "    accuracy                           0.51       150\n",
            "   macro avg       0.53      0.50      0.50       150\n",
            "weighted avg       0.53      0.51      0.50       150\n",
            "\n",
            "\n",
            "0.483 (+/-0.120) for {'max_depth': 3, 'min_samples_split': 4, 'n_estimators': 100}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       bored       0.59      0.36      0.45        36\n",
            "     excited       0.43      0.57      0.49        37\n",
            "     neutral       0.49      0.62      0.55        39\n",
            "    question       0.60      0.47      0.53        38\n",
            "\n",
            "    accuracy                           0.51       150\n",
            "   macro avg       0.53      0.50      0.50       150\n",
            "weighted avg       0.53      0.51      0.50       150\n",
            "\n",
            "\n",
            "0.477 (+/-0.091) for {'max_depth': 3, 'min_samples_split': 4, 'n_estimators': 200}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       bored       0.59      0.36      0.45        36\n",
            "     excited       0.43      0.57      0.49        37\n",
            "     neutral       0.49      0.62      0.55        39\n",
            "    question       0.60      0.47      0.53        38\n",
            "\n",
            "    accuracy                           0.51       150\n",
            "   macro avg       0.53      0.50      0.50       150\n",
            "weighted avg       0.53      0.51      0.50       150\n",
            "\n",
            "\n",
            "0.454 (+/-0.106) for {'max_depth': 4, 'min_samples_split': 2, 'n_estimators': 50}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       bored       0.59      0.36      0.45        36\n",
            "     excited       0.43      0.57      0.49        37\n",
            "     neutral       0.49      0.62      0.55        39\n",
            "    question       0.60      0.47      0.53        38\n",
            "\n",
            "    accuracy                           0.51       150\n",
            "   macro avg       0.53      0.50      0.50       150\n",
            "weighted avg       0.53      0.51      0.50       150\n",
            "\n",
            "\n",
            "0.489 (+/-0.101) for {'max_depth': 4, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       bored       0.59      0.36      0.45        36\n",
            "     excited       0.43      0.57      0.49        37\n",
            "     neutral       0.49      0.62      0.55        39\n",
            "    question       0.60      0.47      0.53        38\n",
            "\n",
            "    accuracy                           0.51       150\n",
            "   macro avg       0.53      0.50      0.50       150\n",
            "weighted avg       0.53      0.51      0.50       150\n",
            "\n",
            "\n",
            "0.489 (+/-0.091) for {'max_depth': 4, 'min_samples_split': 2, 'n_estimators': 200}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       bored       0.59      0.36      0.45        36\n",
            "     excited       0.43      0.57      0.49        37\n",
            "     neutral       0.49      0.62      0.55        39\n",
            "    question       0.60      0.47      0.53        38\n",
            "\n",
            "    accuracy                           0.51       150\n",
            "   macro avg       0.53      0.50      0.50       150\n",
            "weighted avg       0.53      0.51      0.50       150\n",
            "\n",
            "\n",
            "0.471 (+/-0.101) for {'max_depth': 4, 'min_samples_split': 3, 'n_estimators': 50}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       bored       0.59      0.36      0.45        36\n",
            "     excited       0.43      0.57      0.49        37\n",
            "     neutral       0.49      0.62      0.55        39\n",
            "    question       0.60      0.47      0.53        38\n",
            "\n",
            "    accuracy                           0.51       150\n",
            "   macro avg       0.53      0.50      0.50       150\n",
            "weighted avg       0.53      0.51      0.50       150\n",
            "\n",
            "\n",
            "0.471 (+/-0.110) for {'max_depth': 4, 'min_samples_split': 3, 'n_estimators': 100}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       bored       0.59      0.36      0.45        36\n",
            "     excited       0.43      0.57      0.49        37\n",
            "     neutral       0.49      0.62      0.55        39\n",
            "    question       0.60      0.47      0.53        38\n",
            "\n",
            "    accuracy                           0.51       150\n",
            "   macro avg       0.53      0.50      0.50       150\n",
            "weighted avg       0.53      0.51      0.50       150\n",
            "\n",
            "\n",
            "0.474 (+/-0.101) for {'max_depth': 4, 'min_samples_split': 3, 'n_estimators': 200}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       bored       0.59      0.36      0.45        36\n",
            "     excited       0.43      0.57      0.49        37\n",
            "     neutral       0.49      0.62      0.55        39\n",
            "    question       0.60      0.47      0.53        38\n",
            "\n",
            "    accuracy                           0.51       150\n",
            "   macro avg       0.53      0.50      0.50       150\n",
            "weighted avg       0.53      0.51      0.50       150\n",
            "\n",
            "\n",
            "0.471 (+/-0.121) for {'max_depth': 4, 'min_samples_split': 4, 'n_estimators': 50}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       bored       0.59      0.36      0.45        36\n",
            "     excited       0.43      0.57      0.49        37\n",
            "     neutral       0.49      0.62      0.55        39\n",
            "    question       0.60      0.47      0.53        38\n",
            "\n",
            "    accuracy                           0.51       150\n",
            "   macro avg       0.53      0.50      0.50       150\n",
            "weighted avg       0.53      0.51      0.50       150\n",
            "\n",
            "\n",
            "0.466 (+/-0.109) for {'max_depth': 4, 'min_samples_split': 4, 'n_estimators': 100}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       bored       0.59      0.36      0.45        36\n",
            "     excited       0.43      0.57      0.49        37\n",
            "     neutral       0.49      0.62      0.55        39\n",
            "    question       0.60      0.47      0.53        38\n",
            "\n",
            "    accuracy                           0.51       150\n",
            "   macro avg       0.53      0.50      0.50       150\n",
            "weighted avg       0.53      0.51      0.50       150\n",
            "\n",
            "\n",
            "0.483 (+/-0.093) for {'max_depth': 4, 'min_samples_split': 4, 'n_estimators': 200}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       bored       0.59      0.36      0.45        36\n",
            "     excited       0.43      0.57      0.49        37\n",
            "     neutral       0.49      0.62      0.55        39\n",
            "    question       0.60      0.47      0.53        38\n",
            "\n",
            "    accuracy                           0.51       150\n",
            "   macro avg       0.53      0.50      0.50       150\n",
            "weighted avg       0.53      0.51      0.50       150\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JXgFbRMDoT7"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "According to the results of the above cell, the random forest classifier was able to obtain the highest accuracy of 0.491 with the hyperparameters: 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 100."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObIDFkGSfuYa"
      },
      "source": [
        "# 2 Advanced solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPKwv7OcMxBq"
      },
      "source": [
        "Using the same dataset, a support vector machine learning model will be developed to identify prime numbers in the dataset. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F76SDyXTHmEJ"
      },
      "source": [
        "The next cell firstly defines a function that calculates whether the number is prime or not by returning true or false."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Otbe8hAs7AmO"
      },
      "source": [
        "def isPrime(yi):\n",
        "  if yi == 2 or yi == 3: return True\n",
        "  if yi < 2 or yi%2 == 0: return False\n",
        "  if yi < 9: return True\n",
        "  if yi%3 == 0: return False\n",
        "  r = int(yi**0.5)\n",
        "  f = 5\n",
        "  while f <= r:\n",
        "    print('\\t',f)\n",
        "    if yi % f == 0: return False\n",
        "    if yi % (f+2) == 0: return False\n",
        "    f += 6\n",
        "  return True    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3BGxGXQH-2K"
      },
      "source": [
        "A similar function to the previous solution will also be used to obtain the necessary features. The function will include an if statement to check if number is prime."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wHfDZj81Bph"
      },
      "source": [
        "def get_Xy(files,labels_file,scale_audio=False):\n",
        "  X,y =[],[]\n",
        "  for file in tqdm(files):\n",
        "    fileID = file.split('/')[-1]\n",
        "    yi = list(labels_file[labels_file['File ID']==fileID]['digit_label'])[0]\n",
        "    if (isPrime(yi)==False):\n",
        "      continue\n",
        "    else:\n",
        "      fs = None # if None, fs would be 22050\n",
        "      x, fs = librosa.load(file,sr=fs)\n",
        "      if scale_audio: x = x/np.max(np.abs(x))\n",
        "      f0, voiced_flag = getPitch(x,fs,winLen=0.02)\n",
        "      \n",
        "      power = np.sum(x**2)/len(x)\n",
        "      pitch_mean = np.nanmean(f0) if np.mean(np.isnan(f0))<1 else 0\n",
        "      pitch_std  = np.nanstd(f0) if np.mean(np.isnan(f0))<1 else 0\n",
        "      voiced_fr = np.mean(voiced_flag)\n",
        "\n",
        "      xi = [power,pitch_mean,pitch_std,voiced_fr]\n",
        "      X.append(xi)\n",
        "      y.append(yi)\n",
        "  return np.array(X),np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VaaKBFE3Cor",
        "outputId": "58cd1c54-22c9-43b7-8d98-60adcb0952a2"
      },
      "source": [
        "X,y = get_Xy(files[:500],labels_file=labels,scale_audio=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:39<00:00, 12.61it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "io6reY-15UAF",
        "outputId": "06a3b99f-0bbf-4aa9-b0be-43f8872e7769"
      },
      "source": [
        "print('The shape of X is', X.shape) \n",
        "print('The shape of y is', y.shape)\n",
        "print('The labels vector is', y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of X is (139, 4)\n",
            "The shape of y is (139,)\n",
            "The labels vector is [ 3  5  5  5  2 17 19 13 11 19 13  5  2 19 19  7 17 13  7 11 11 17 11  2\n",
            " 11  3 11  5 13 13 13  3 17 17  5 11 17 13  7  5  3  5  5 19  3  7  3 19\n",
            " 19 17  7  5 13 17  3 19  3  5  5  2  5  2  3  2 11  5  7  7 13 17 17 17\n",
            " 19 11  2  7  2  7 19 17 13  7 11 19  7 11  7  3  7 13  3 13  5  3  3 11\n",
            " 17 13  7 11  5  7 17  3 13 19 13 19 17 11 17  3 17 11 11  3  3  7 17  5\n",
            " 17  5 19  5 13  2 17  3  7 17 11 13  7 17 13  2 13  5  3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCDVJBO9IjqC"
      },
      "source": [
        "As seen in the above output, the labels are only prime numbers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXuLELbr5Duw"
      },
      "source": [
        "Creating SVM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvMoA1NU4uic",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "outputId": "77236220-06a5-43b9-fe49-e8bd4b5670ff"
      },
      "source": [
        "from sklearn import datasets, metrics, model_selection, svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.3)\n",
        "X_train.shape, X_val.shape, y_train.shape, y_val.shape\n",
        "\n",
        "#normalising \n",
        "mean = X_train.mean(0)\n",
        "sd =  X_train.std(0)\n",
        "X_train = (X_train-mean)/sd\n",
        "X_val  = (X_val-mean)/sd\n",
        "\n",
        "#svm\n",
        "model  = svm.SVC(C=1,gamma=2)\n",
        "model.fit(X_train,y_train)\n",
        "yt_p = model.predict(X_train)\n",
        "yv_p = model.predict(X_val)\n",
        "\n",
        "print('Training Accuracy', np.mean(yt_p==y_train))\n",
        "print('Validation  Accuracy', np.mean(yv_p==y_val))\n",
        "\n",
        "title='Confusion matrix'\n",
        "disp = plot_confusion_matrix(model, X_val, y_val,cmap=plt.cm.Blues)\n",
        "disp.ax_.set_title(title)\n",
        "print(title)\n",
        "print(disp.confusion_matrix)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy 0.8041237113402062\n",
            "Validation  Accuracy 0.11904761904761904\n",
            "Confusion matrix\n",
            "[[0 1 0 0 0 1 0 0]\n",
            " [0 1 0 0 3 0 0 0]\n",
            " [0 4 0 1 1 1 0 0]\n",
            " [0 1 2 1 0 2 0 0]\n",
            " [0 1 0 0 1 0 1 0]\n",
            " [0 2 1 1 0 1 0 0]\n",
            " [0 2 1 2 3 0 1 0]\n",
            " [0 3 0 0 1 0 2 0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oeEzrvALes2"
      },
      "source": [
        "As you can see, the training accuracy is high however the validation accuracy is incredibly low indicating that the model is overfitting. Thus to improve the accuracy, GridSearch will be used once again. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4wFspkfRVVU",
        "outputId": "bbd02079-154d-4286-ddae-6f5f2ed14a98"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=0)\n",
        "\n",
        "#normalisation\n",
        "mean = X_train.mean(0)\n",
        "sd =  X_train.std(0)\n",
        "\n",
        "X_train = (X_train-mean)/sd\n",
        "X_test  = (X_test-mean)/sd\n",
        "\n",
        "#parameters being tested\n",
        "tuned_parameters = param_grid = {\n",
        "    'C': [0.01,0.1,1,10,100],\n",
        "    'gamma': [2,3,4],\n",
        "    'kernel': ['rbf','linear']\n",
        "}\n",
        "\n",
        "print(\"Tuning hyper-parameters for accuracy\")\n",
        "print()\n",
        "\n",
        "clf = GridSearchCV(SVC(), tuned_parameters, scoring='accuracy')\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters set found on development set:\")\n",
        "print()\n",
        "print(clf.best_params_)\n",
        "print()\n",
        "print(\"Grid scores on development set:\")\n",
        "print()\n",
        "means = clf.cv_results_['mean_test_score']\n",
        "stds = clf.cv_results_['std_test_score']\n",
        "#printing out accuracy details for each type of SVM\n",
        "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "  print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
        "  print()\n",
        "  print(\"Detailed classification report:\")\n",
        "  print()\n",
        "  y_true, y_pred = y_test, clf.predict(X_test)\n",
        "  print(classification_report(y_true, y_pred))\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tuning hyper-parameters for accuracy\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'C': 10, 'gamma': 3, 'kernel': 'rbf'}\n",
            "\n",
            "Grid scores on development set:\n",
            "\n",
            "0.165 (+/-0.036) for {'C': 0.01, 'gamma': 2, 'kernel': 'rbf'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       0.11      0.20      0.14         5\n",
            "           5       0.00      0.00      0.00         6\n",
            "           7       0.33      0.20      0.25         5\n",
            "          11       0.00      0.00      0.00         6\n",
            "          13       0.33      0.14      0.20         7\n",
            "          17       0.13      0.33      0.19         6\n",
            "          19       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.12        42\n",
            "   macro avg       0.11      0.11      0.10        42\n",
            "weighted avg       0.13      0.12      0.11        42\n",
            "\n",
            "\n",
            "0.165 (+/-0.036) for {'C': 0.01, 'gamma': 2, 'kernel': 'linear'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       0.11      0.20      0.14         5\n",
            "           5       0.00      0.00      0.00         6\n",
            "           7       0.33      0.20      0.25         5\n",
            "          11       0.00      0.00      0.00         6\n",
            "          13       0.33      0.14      0.20         7\n",
            "          17       0.13      0.33      0.19         6\n",
            "          19       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.12        42\n",
            "   macro avg       0.11      0.11      0.10        42\n",
            "weighted avg       0.13      0.12      0.11        42\n",
            "\n",
            "\n",
            "0.165 (+/-0.036) for {'C': 0.01, 'gamma': 3, 'kernel': 'rbf'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       0.11      0.20      0.14         5\n",
            "           5       0.00      0.00      0.00         6\n",
            "           7       0.33      0.20      0.25         5\n",
            "          11       0.00      0.00      0.00         6\n",
            "          13       0.33      0.14      0.20         7\n",
            "          17       0.13      0.33      0.19         6\n",
            "          19       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.12        42\n",
            "   macro avg       0.11      0.11      0.10        42\n",
            "weighted avg       0.13      0.12      0.11        42\n",
            "\n",
            "\n",
            "0.165 (+/-0.036) for {'C': 0.01, 'gamma': 3, 'kernel': 'linear'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       0.11      0.20      0.14         5\n",
            "           5       0.00      0.00      0.00         6\n",
            "           7       0.33      0.20      0.25         5\n",
            "          11       0.00      0.00      0.00         6\n",
            "          13       0.33      0.14      0.20         7\n",
            "          17       0.13      0.33      0.19         6\n",
            "          19       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.12        42\n",
            "   macro avg       0.11      0.11      0.10        42\n",
            "weighted avg       0.13      0.12      0.11        42\n",
            "\n",
            "\n",
            "0.165 (+/-0.036) for {'C': 0.01, 'gamma': 4, 'kernel': 'rbf'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       0.11      0.20      0.14         5\n",
            "           5       0.00      0.00      0.00         6\n",
            "           7       0.33      0.20      0.25         5\n",
            "          11       0.00      0.00      0.00         6\n",
            "          13       0.33      0.14      0.20         7\n",
            "          17       0.13      0.33      0.19         6\n",
            "          19       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.12        42\n",
            "   macro avg       0.11      0.11      0.10        42\n",
            "weighted avg       0.13      0.12      0.11        42\n",
            "\n",
            "\n",
            "0.165 (+/-0.036) for {'C': 0.01, 'gamma': 4, 'kernel': 'linear'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       0.11      0.20      0.14         5\n",
            "           5       0.00      0.00      0.00         6\n",
            "           7       0.33      0.20      0.25         5\n",
            "          11       0.00      0.00      0.00         6\n",
            "          13       0.33      0.14      0.20         7\n",
            "          17       0.13      0.33      0.19         6\n",
            "          19       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.12        42\n",
            "   macro avg       0.11      0.11      0.10        42\n",
            "weighted avg       0.13      0.12      0.11        42\n",
            "\n",
            "\n",
            "0.165 (+/-0.036) for {'C': 0.1, 'gamma': 2, 'kernel': 'rbf'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       0.11      0.20      0.14         5\n",
            "           5       0.00      0.00      0.00         6\n",
            "           7       0.33      0.20      0.25         5\n",
            "          11       0.00      0.00      0.00         6\n",
            "          13       0.33      0.14      0.20         7\n",
            "          17       0.13      0.33      0.19         6\n",
            "          19       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.12        42\n",
            "   macro avg       0.11      0.11      0.10        42\n",
            "weighted avg       0.13      0.12      0.11        42\n",
            "\n",
            "\n",
            "0.134 (+/-0.140) for {'C': 0.1, 'gamma': 2, 'kernel': 'linear'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       0.11      0.20      0.14         5\n",
            "           5       0.00      0.00      0.00         6\n",
            "           7       0.33      0.20      0.25         5\n",
            "          11       0.00      0.00      0.00         6\n",
            "          13       0.33      0.14      0.20         7\n",
            "          17       0.13      0.33      0.19         6\n",
            "          19       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.12        42\n",
            "   macro avg       0.11      0.11      0.10        42\n",
            "weighted avg       0.13      0.12      0.11        42\n",
            "\n",
            "\n",
            "0.165 (+/-0.036) for {'C': 0.1, 'gamma': 3, 'kernel': 'rbf'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       0.11      0.20      0.14         5\n",
            "           5       0.00      0.00      0.00         6\n",
            "           7       0.33      0.20      0.25         5\n",
            "          11       0.00      0.00      0.00         6\n",
            "          13       0.33      0.14      0.20         7\n",
            "          17       0.13      0.33      0.19         6\n",
            "          19       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.12        42\n",
            "   macro avg       0.11      0.11      0.10        42\n",
            "weighted avg       0.13      0.12      0.11        42\n",
            "\n",
            "\n",
            "0.134 (+/-0.140) for {'C': 0.1, 'gamma': 3, 'kernel': 'linear'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       0.11      0.20      0.14         5\n",
            "           5       0.00      0.00      0.00         6\n",
            "           7       0.33      0.20      0.25         5\n",
            "          11       0.00      0.00      0.00         6\n",
            "          13       0.33      0.14      0.20         7\n",
            "          17       0.13      0.33      0.19         6\n",
            "          19       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.12        42\n",
            "   macro avg       0.11      0.11      0.10        42\n",
            "weighted avg       0.13      0.12      0.11        42\n",
            "\n",
            "\n",
            "0.165 (+/-0.036) for {'C': 0.1, 'gamma': 4, 'kernel': 'rbf'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       0.11      0.20      0.14         5\n",
            "           5       0.00      0.00      0.00         6\n",
            "           7       0.33      0.20      0.25         5\n",
            "          11       0.00      0.00      0.00         6\n",
            "          13       0.33      0.14      0.20         7\n",
            "          17       0.13      0.33      0.19         6\n",
            "          19       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.12        42\n",
            "   macro avg       0.11      0.11      0.10        42\n",
            "weighted avg       0.13      0.12      0.11        42\n",
            "\n",
            "\n",
            "0.134 (+/-0.140) for {'C': 0.1, 'gamma': 4, 'kernel': 'linear'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       0.11      0.20      0.14         5\n",
            "           5       0.00      0.00      0.00         6\n",
            "           7       0.33      0.20      0.25         5\n",
            "          11       0.00      0.00      0.00         6\n",
            "          13       0.33      0.14      0.20         7\n",
            "          17       0.13      0.33      0.19         6\n",
            "          19       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.12        42\n",
            "   macro avg       0.11      0.11      0.10        42\n",
            "weighted avg       0.13      0.12      0.11        42\n",
            "\n",
            "\n",
            "0.145 (+/-0.045) for {'C': 1, 'gamma': 2, 'kernel': 'rbf'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       0.11      0.20      0.14         5\n",
            "           5       0.00      0.00      0.00         6\n",
            "           7       0.33      0.20      0.25         5\n",
            "          11       0.00      0.00      0.00         6\n",
            "          13       0.33      0.14      0.20         7\n",
            "          17       0.13      0.33      0.19         6\n",
            "          19       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.12        42\n",
            "   macro avg       0.11      0.11      0.10        42\n",
            "weighted avg       0.13      0.12      0.11        42\n",
            "\n",
            "\n",
            "0.062 (+/-0.104) for {'C': 1, 'gamma': 2, 'kernel': 'linear'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       0.11      0.20      0.14         5\n",
            "           5       0.00      0.00      0.00         6\n",
            "           7       0.33      0.20      0.25         5\n",
            "          11       0.00      0.00      0.00         6\n",
            "          13       0.33      0.14      0.20         7\n",
            "          17       0.13      0.33      0.19         6\n",
            "          19       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.12        42\n",
            "   macro avg       0.11      0.11      0.10        42\n",
            "weighted avg       0.13      0.12      0.11        42\n",
            "\n",
            "\n",
            "0.134 (+/-0.079) for {'C': 1, 'gamma': 3, 'kernel': 'rbf'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       0.11      0.20      0.14         5\n",
            "           5       0.00      0.00      0.00         6\n",
            "           7       0.33      0.20      0.25         5\n",
            "          11       0.00      0.00      0.00         6\n",
            "          13       0.33      0.14      0.20         7\n",
            "          17       0.13      0.33      0.19         6\n",
            "          19       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.12        42\n",
            "   macro avg       0.11      0.11      0.10        42\n",
            "weighted avg       0.13      0.12      0.11        42\n",
            "\n",
            "\n",
            "0.062 (+/-0.104) for {'C': 1, 'gamma': 3, 'kernel': 'linear'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       0.11      0.20      0.14         5\n",
            "           5       0.00      0.00      0.00         6\n",
            "           7       0.33      0.20      0.25         5\n",
            "          11       0.00      0.00      0.00         6\n",
            "          13       0.33      0.14      0.20         7\n",
            "          17       0.13      0.33      0.19         6\n",
            "          19       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.12        42\n",
            "   macro avg       0.11      0.11      0.10        42\n",
            "weighted avg       0.13      0.12      0.11        42\n",
            "\n",
            "\n",
            "0.165 (+/-0.078) for {'C': 1, 'gamma': 4, 'kernel': 'rbf'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       0.11      0.20      0.14         5\n",
            "           5       0.00      0.00      0.00         6\n",
            "           7       0.33      0.20      0.25         5\n",
            "          11       0.00      0.00      0.00         6\n",
            "          13       0.33      0.14      0.20         7\n",
            "          17       0.13      0.33      0.19         6\n",
            "          19       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.12        42\n",
            "   macro avg       0.11      0.11      0.10        42\n",
            "weighted avg       0.13      0.12      0.11        42\n",
            "\n",
            "\n",
            "0.062 (+/-0.104) for {'C': 1, 'gamma': 4, 'kernel': 'linear'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       0.11      0.20      0.14         5\n",
            "           5       0.00      0.00      0.00         6\n",
            "           7       0.33      0.20      0.25         5\n",
            "          11       0.00      0.00      0.00         6\n",
            "          13       0.33      0.14      0.20         7\n",
            "          17       0.13      0.33      0.19         6\n",
            "          19       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.12        42\n",
            "   macro avg       0.11      0.11      0.10        42\n",
            "weighted avg       0.13      0.12      0.11        42\n",
            "\n",
            "\n",
            "0.174 (+/-0.097) for {'C': 10, 'gamma': 2, 'kernel': 'rbf'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       0.11      0.20      0.14         5\n",
            "           5       0.00      0.00      0.00         6\n",
            "           7       0.33      0.20      0.25         5\n",
            "          11       0.00      0.00      0.00         6\n",
            "          13       0.33      0.14      0.20         7\n",
            "          17       0.13      0.33      0.19         6\n",
            "          19       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.12        42\n",
            "   macro avg       0.11      0.11      0.10        42\n",
            "weighted avg       0.13      0.12      0.11        42\n",
            "\n",
            "\n",
            "0.062 (+/-0.104) for {'C': 10, 'gamma': 2, 'kernel': 'linear'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       0.11      0.20      0.14         5\n",
            "           5       0.00      0.00      0.00         6\n",
            "           7       0.33      0.20      0.25         5\n",
            "          11       0.00      0.00      0.00         6\n",
            "          13       0.33      0.14      0.20         7\n",
            "          17       0.13      0.33      0.19         6\n",
            "          19       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.12        42\n",
            "   macro avg       0.11      0.11      0.10        42\n",
            "weighted avg       0.13      0.12      0.11        42\n",
            "\n",
            "\n",
            "0.196 (+/-0.100) for {'C': 10, 'gamma': 3, 'kernel': 'rbf'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       0.11      0.20      0.14         5\n",
            "           5       0.00      0.00      0.00         6\n",
            "           7       0.33      0.20      0.25         5\n",
            "          11       0.00      0.00      0.00         6\n",
            "          13       0.33      0.14      0.20         7\n",
            "          17       0.13      0.33      0.19         6\n",
            "          19       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.12        42\n",
            "   macro avg       0.11      0.11      0.10        42\n",
            "weighted avg       0.13      0.12      0.11        42\n",
            "\n",
            "\n",
            "0.062 (+/-0.104) for {'C': 10, 'gamma': 3, 'kernel': 'linear'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       0.11      0.20      0.14         5\n",
            "           5       0.00      0.00      0.00         6\n",
            "           7       0.33      0.20      0.25         5\n",
            "          11       0.00      0.00      0.00         6\n",
            "          13       0.33      0.14      0.20         7\n",
            "          17       0.13      0.33      0.19         6\n",
            "          19       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.12        42\n",
            "   macro avg       0.11      0.11      0.10        42\n",
            "weighted avg       0.13      0.12      0.11        42\n",
            "\n",
            "\n",
            "0.196 (+/-0.077) for {'C': 10, 'gamma': 4, 'kernel': 'rbf'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       0.11      0.20      0.14         5\n",
            "           5       0.00      0.00      0.00         6\n",
            "           7       0.33      0.20      0.25         5\n",
            "          11       0.00      0.00      0.00         6\n",
            "          13       0.33      0.14      0.20         7\n",
            "          17       0.13      0.33      0.19         6\n",
            "          19       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.12        42\n",
            "   macro avg       0.11      0.11      0.10        42\n",
            "weighted avg       0.13      0.12      0.11        42\n",
            "\n",
            "\n",
            "0.062 (+/-0.104) for {'C': 10, 'gamma': 4, 'kernel': 'linear'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       0.11      0.20      0.14         5\n",
            "           5       0.00      0.00      0.00         6\n",
            "           7       0.33      0.20      0.25         5\n",
            "          11       0.00      0.00      0.00         6\n",
            "          13       0.33      0.14      0.20         7\n",
            "          17       0.13      0.33      0.19         6\n",
            "          19       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.12        42\n",
            "   macro avg       0.11      0.11      0.10        42\n",
            "weighted avg       0.13      0.12      0.11        42\n",
            "\n",
            "\n",
            "0.164 (+/-0.070) for {'C': 100, 'gamma': 2, 'kernel': 'rbf'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       0.11      0.20      0.14         5\n",
            "           5       0.00      0.00      0.00         6\n",
            "           7       0.33      0.20      0.25         5\n",
            "          11       0.00      0.00      0.00         6\n",
            "          13       0.33      0.14      0.20         7\n",
            "          17       0.13      0.33      0.19         6\n",
            "          19       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.12        42\n",
            "   macro avg       0.11      0.11      0.10        42\n",
            "weighted avg       0.13      0.12      0.11        42\n",
            "\n",
            "\n",
            "0.062 (+/-0.121) for {'C': 100, 'gamma': 2, 'kernel': 'linear'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       0.11      0.20      0.14         5\n",
            "           5       0.00      0.00      0.00         6\n",
            "           7       0.33      0.20      0.25         5\n",
            "          11       0.00      0.00      0.00         6\n",
            "          13       0.33      0.14      0.20         7\n",
            "          17       0.13      0.33      0.19         6\n",
            "          19       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.12        42\n",
            "   macro avg       0.11      0.11      0.10        42\n",
            "weighted avg       0.13      0.12      0.11        42\n",
            "\n",
            "\n",
            "0.196 (+/-0.100) for {'C': 100, 'gamma': 3, 'kernel': 'rbf'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       0.11      0.20      0.14         5\n",
            "           5       0.00      0.00      0.00         6\n",
            "           7       0.33      0.20      0.25         5\n",
            "          11       0.00      0.00      0.00         6\n",
            "          13       0.33      0.14      0.20         7\n",
            "          17       0.13      0.33      0.19         6\n",
            "          19       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.12        42\n",
            "   macro avg       0.11      0.11      0.10        42\n",
            "weighted avg       0.13      0.12      0.11        42\n",
            "\n",
            "\n",
            "0.062 (+/-0.121) for {'C': 100, 'gamma': 3, 'kernel': 'linear'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       0.11      0.20      0.14         5\n",
            "           5       0.00      0.00      0.00         6\n",
            "           7       0.33      0.20      0.25         5\n",
            "          11       0.00      0.00      0.00         6\n",
            "          13       0.33      0.14      0.20         7\n",
            "          17       0.13      0.33      0.19         6\n",
            "          19       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.12        42\n",
            "   macro avg       0.11      0.11      0.10        42\n",
            "weighted avg       0.13      0.12      0.11        42\n",
            "\n",
            "\n",
            "0.196 (+/-0.077) for {'C': 100, 'gamma': 4, 'kernel': 'rbf'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       0.11      0.20      0.14         5\n",
            "           5       0.00      0.00      0.00         6\n",
            "           7       0.33      0.20      0.25         5\n",
            "          11       0.00      0.00      0.00         6\n",
            "          13       0.33      0.14      0.20         7\n",
            "          17       0.13      0.33      0.19         6\n",
            "          19       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.12        42\n",
            "   macro avg       0.11      0.11      0.10        42\n",
            "weighted avg       0.13      0.12      0.11        42\n",
            "\n",
            "\n",
            "0.062 (+/-0.121) for {'C': 100, 'gamma': 4, 'kernel': 'linear'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       0.11      0.20      0.14         5\n",
            "           5       0.00      0.00      0.00         6\n",
            "           7       0.33      0.20      0.25         5\n",
            "          11       0.00      0.00      0.00         6\n",
            "          13       0.33      0.14      0.20         7\n",
            "          17       0.13      0.33      0.19         6\n",
            "          19       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.12        42\n",
            "   macro avg       0.11      0.11      0.10        42\n",
            "weighted avg       0.13      0.12      0.11        42\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtLncishb8tB"
      },
      "source": [
        "#Conclusion\n",
        "\n",
        "From the results shown above, the best parameters for the SVM model is {'C': 10, 'gamma': 3, 'kernel': 'rbf'}. It obtained the highest accuracy of 0.196.\n"
      ]
    }
  ]
}
